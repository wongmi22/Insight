{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f_pre = []\n",
    "f_avg = []\n",
    "f_tru = []\n",
    "prediction_list = []\n",
    "average_list = []\n",
    "true_list = []\n",
    "\n",
    "for Rki in df_Rk.Rk:\n",
    "    Rk = str(Rki)\n",
    "    print Rk\n",
    "    cmd_target_2015 = 'SELECT PTS,3P,TRB,AST,STL,BLK,TOV FROM NBA_player_data WHERE Player_Name IN (\\'' + player + '\\') AND Year IN (\\'2015\\') AND Rk < '+Rk+' ;'\n",
    "    cmd_target_2014 = 'SELECT PTS,3P,TRB,AST,STL,BLK,TOV FROM NBA_player_data WHERE Player_Name IN (\\'' + player + '\\') AND Year IN (\\'2014\\') AND Rk >= '+Rk+' ;'\n",
    "    cmd_train_2015 = 'SELECT Rk,Home_Away,DateDiff,TeamID,Win,OPPG,OTPR,O3Ppercent,ORPG,OBPG,OSPG,DEF,O3PM,OFGpercent,OTPG,OAPG,TPG,SPG,TRBR,OBLKpercent FROM NBA_player_data WHERE Player_Name IN (\\'' + player + '\\') AND Year IN (\\'2015\\') AND Rk < '+Rk+';'\n",
    "    cmd_train_2014 = 'SELECT Rk,Home_Away,DateDiff,TeamID,Win,OPPG,OTPR,O3Ppercent,ORPG,OBPG,OSPG,DEF,O3PM,OFGpercent,OTPG,OAPG,TPG,SPG,TRBR,OBLKpercent FROM NBA_player_data WHERE Player_Name IN (\\'' + player + '\\') AND Year IN (\\'2014\\') AND Rk >= '+Rk+';'\n",
    "    cmd_operate = 'SELECT Rk,Home_Away,DateDiff,TeamID,Win,OPPG,OTPR,O3Ppercent,ORPG,OBPG,OSPG,DEF,O3PM,OFGpercent,OTPG,OAPG,TPG,SPG,TRBR,OBLKpercent FROM NBA_player_data WHERE Player_Name IN (\\'' + player + '\\') AND Year IN (\\'2015\\') AND Rk = '+Rk+';'\n",
    "    cmd_truth = 'SELECT PTS,3P,TRB,AST,STL,BLK,TOV FROM NBA_player_data WHERE Player_Name IN (\\'' + player + '\\') AND Year IN (\\'2015\\') AND Rk = '+Rk+' ;'\n",
    "\n",
    "    df_target_2015 = pd.read_sql(cmd_target_2015, con=conn) \n",
    "    df_target_2014 = pd.read_sql(cmd_target_2014, con=conn) \n",
    "    df_train_2015 = pd.read_sql(cmd_train_2015, con=conn) \n",
    "    df_train_2014 = pd.read_sql(cmd_train_2014, con=conn) \n",
    "    df_operate = pd.read_sql(cmd_operate, con=conn) \n",
    "    df_truth = pd.read_sql(cmd_truth, con=conn) \n",
    "    df_truth = df_truth.applymap(lambda x: float(x))\n",
    "\n",
    "    df_target=pd.concat([df_target_2014, df_target_2015],ignore_index=True)\n",
    "    df_train=pd.concat([df_train_2014, df_train_2015],ignore_index=True)\n",
    "    df_target = df_target.applymap(lambda x:float(x))\n",
    "    df_train = df_train.applymap(lambda x:float(x))\n",
    "    df_target_2015 = df_target_2015.applymap(lambda x: float(x))\n",
    "\n",
    "    df_inquire = df_operate.applymap(lambda x:float(x))\n",
    "    df_train_plus_inquire=pd.concat([df_train, df_inquire])\n",
    "    df_raw = df_train_plus_inquire.reindex()\n",
    "    df_raw_scaled = df_raw.copy()\n",
    "    df_raw_scaled = df_raw_scaled.applymap(lambda x: np.log(x))\n",
    "    df_raw_transform = df_raw.copy()\n",
    "\n",
    "    df_raw_scaled = df_raw_scaled.apply(lambda x:preprocessing.StandardScaler().fit(x).transform(x))\n",
    "    df_raw_transform = df_raw_transform.apply(lambda x:preprocessing.StandardScaler().fit(x))\n",
    "\n",
    "    pca = PCA()\n",
    "    pca.fit(df_raw_scaled)\n",
    "    pca.n_components=7\n",
    "    train_reduced = pca.fit_transform(df_raw_scaled)\n",
    "    df_train_reduced=pd.DataFrame(train_reduced)\n",
    "    df_evaluate = df_train_reduced.tail(1)\n",
    "    df_train_scaled = df_train_reduced.iloc[:-1]\n",
    "\n",
    "\n",
    "    # rf = RandomForestRegressor(n_estimators=100)\n",
    "    # rf.fit(df_train_scaled, df_target)\n",
    "    # predictions = rf.predict(df_evaluate).round()[0]\n",
    "\n",
    "    PTS = LinR()\n",
    "    PTS.fit(df_train_scaled, df_target.PTS)\n",
    "    pPTS = PTS.predict(df_evaluate)\n",
    "    REB = LinR()\n",
    "    REB.fit(df_train_scaled, df_target.TRB)\n",
    "    pREB = REB.predict(df_evaluate)\n",
    "    AST = LinR()\n",
    "    AST.fit(df_train_scaled, df_target.AST)\n",
    "    pAST = AST.predict(df_evaluate)\n",
    "    TP = LinR()\n",
    "    TP.fit(df_train_scaled, df_target['3P'])\n",
    "    pTP = TP.predict(df_evaluate)\n",
    "    STL = LinR()\n",
    "    STL.fit(df_train_scaled, df_target.STL)\n",
    "    pSTL = STL.predict(df_evaluate)\n",
    "    BLK = LinR()\n",
    "    BLK.fit(df_train_scaled, df_target.BLK)\n",
    "    pBLK = BLK.predict(df_evaluate)\n",
    "    TOV = LinR()\n",
    "    TOV.fit(df_train_scaled, df_target.TOV)\n",
    "    pTOV = TOV.predict(df_evaluate)\n",
    "\n",
    "    predictions = np.asarray([pPTS,pTP,pREB,pAST,pSTL,pBLK,pTOV])\n",
    "\n",
    "    if int(Rk) < 20:\n",
    "        average_stats=df_target.mean()\n",
    "        #average_stats=df_target.mean().round()   \n",
    "    elif int(Rk) >= 20:\n",
    "        #average_stats=df_target_2015.mean().round()\n",
    "        average_stats=df_target_2015.mean()\n",
    "    average_stats=np.asarray(average_stats)\n",
    "    true_stats = np.asarray(df_truth)[0]\n",
    "    fanduel_pre, fanduel_avg, fanduel_tru = get_fanduel(predictions,average_stats,true_stats)\n",
    "    f_pre.append(fanduel_pre)\n",
    "    f_avg.append(fanduel_avg)\n",
    "    f_tru.append(fanduel_tru)\n",
    "    prediction_list.append(predictions)\n",
    "    average_list.append(average_stats)\n",
    "    true_list.append(true_stats)\n",
    "\n",
    "score =[]\n",
    "for i,f in enumerate(f_pre):\n",
    "    s=get_trend(f,f_avg[i],f_tru[i])\n",
    "    score.append(s)\n",
    "a = [x for x in score if x != 2]\n",
    "\n",
    "pts =[]\n",
    "reb = []\n",
    "ast = []\n",
    "tp = []\n",
    "stl =[]\n",
    "blk =[]\n",
    "to =[]\n",
    "for i in range(len(predictions):\n",
    "    p=get_trend(predictions[i][0],average_stats[i][0],true_stats[i][0])\n",
    "    r=get_trend(predictions[i][2],average_stats[i][2],true_stats[i][2])\n",
    "    a=get_trend(predictions[i][3],average_stats[i][3],true_stats[i][3])\n",
    "    tpm=get_trend(predictions[i][1],average_stats[i][1],true_stats[i][1])\n",
    "    s=get_trend(predictions[i][4],average_stats[i][4],true_stats[i][4])\n",
    "    b=get_trend(predictions[i][5],average_stats[i][5],true_stats[i][5])\n",
    "    t=get_trend(predictions[i][6],average_stats[i][6],true_stats[i][6])\n",
    "\n",
    "    pts.append(p)\n",
    "    reb.append(r)\n",
    "    ast.append(a)\n",
    "    tp.append(tpm)\n",
    "    stl.append(s)\n",
    "    blk.append(b)\n",
    "    to.append(t)\n",
    "\n",
    "pts = [x for x in pts if x != 2]\n",
    "reb = [x for x in reb if x != 2]\n",
    "ast = [x for x in ast if x != 2]\n",
    "tp = [x for x in tp if x != 2]\n",
    "stl = [x for x in stl if x != 2]\n",
    "blk = [x for x in blk if x != 2]\n",
    "to = [x for x in to if x != 2]\n",
    "\n",
    "\n",
    "f_accuracy = a.count(1)/len(a)\n",
    "pts_accuracy = pts.count(1)/len(pts)\n",
    "reb_accuracy = reb.count(1)/len(reb)\n",
    "ast_accuracy = ast.count(1)/len(ast)\n",
    "tp_accuracy = tp.count(1)/len(tp)\n",
    "stl_accuracy = stl.count(1)/len(stl)\n",
    "blk_accuracy = blk.count(1)/len(blk)\n",
    "to_accuracy = to.count(1)/len(to)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
